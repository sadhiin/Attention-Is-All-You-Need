{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "seq_len = 4\n",
    "batch_size = 2\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, input_dim)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1536])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv= qkv_layer(x)\n",
    "qkv.shape   # (batch_size, seq_len, 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "\n",
    "\n",
    "plt.bar(x_val, y_val, align='center', color=['blue'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8, 192])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, seq_len, num_heads, 3 * head_dim)\n",
    "\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 192])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape qkv to (batch_size, num_heads, seq_len, head_dim)\n",
    "qkv = qkv.permute(0, 2, 1, 3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 4, 64]),\n",
       " torch.Size([2, 8, 4, 64]),\n",
       " torch.Size([2, 8, 4, 64]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1) # chunking on the last dimension 192/3 = 64\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self attention for Multi-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dk:  64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "print('Dk: ', d_k)\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K shape:  torch.Size([2, 8, 4, 64])\n",
      "K transpose:  torch.Size([64, 4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "print('K shape: ', k.shape)\n",
    "print('K transpose: ', k.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2148,  0.6919],\n",
       "        [-0.1731,  0.1219],\n",
       "        [ 1.2965, -0.8282]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(2, 3)\n",
    "torch.transpose(y, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2148,  0.6919],\n",
       "        [-0.1731,  0.1219],\n",
       "        [ 1.2965, -0.8282]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4, 64])\n",
      "torch.Size([64, 4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(k.shape)\n",
    "print(k.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k.transpose(-1, -2) == k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 64, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).shape # this is the our expected shape for key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.shape, float('-inf')) # create a tensor with -inf\n",
    "mask = torch.triu(mask, diagonal=1) # zero out the lower diagonal\n",
    "mask[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4522,    -inf,    -inf,    -inf],\n",
       "        [ 0.4781, -0.2977,    -inf,    -inf],\n",
       "        [-0.1293,  0.2757, -0.3821,    -inf],\n",
       "        [ 0.3557, -0.2303,  0.1607,  0.2034]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4522,    -inf,    -inf,    -inf],\n",
       "        [ 0.4781, -0.2977,    -inf,    -inf],\n",
       "        [-0.1293,  0.2757, -0.3821,    -inf],\n",
       "        [ 0.3557, -0.2303,  0.1607,  0.2034]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.add_(mask)\n",
    "scaled[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6848, 0.3152, 0.0000, 0.0000],\n",
       "        [0.3053, 0.4577, 0.2371, 0.0000],\n",
       "        [0.3088, 0.1719, 0.2541, 0.2652]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5555, 0.4445, 0.0000, 0.0000],\n",
       "        [0.3750, 0.2786, 0.3464, 0.0000],\n",
       "        [0.1832, 0.2953, 0.2218, 0.2997]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 64])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1186, -0.6649,  0.1325,  0.0415, -0.1031,  0.1242,  0.3478,  0.0068,\n",
       "        -0.4013, -0.5121,  0.5378,  1.1685,  0.3112,  0.4116, -0.3756, -0.3707,\n",
       "         0.9274,  0.1766,  0.2467,  0.8220, -0.2806,  0.8744, -0.1558, -0.5661,\n",
       "        -0.4433, -0.1975,  0.8040, -0.4103,  0.5253, -0.0538, -0.2255,  0.2669,\n",
       "         0.5358,  0.1524, -0.4793, -0.7805, -0.2239, -0.4174, -0.2479,  0.1650,\n",
       "        -0.1780, -0.1634,  0.1852, -0.3613, -0.2637, -0.6689,  0.5874,  0.0755,\n",
       "        -0.2933, -0.0686, -0.2986,  0.1494,  0.5729, -0.2892,  0.4499,  0.3463,\n",
       "         0.1581,  0.2528,  0.6209, -0.4304,  0.0747, -0.1158,  0.3102,  0.5137],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faction Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 4, 4]), torch.Size([2, 8, 4, 64]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6848, 0.3152, 0.0000, 0.0000],\n",
       "        [0.3053, 0.4577, 0.2371, 0.0000],\n",
       "        [0.3088, 0.1719, 0.2541, 0.2652]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6852, -0.3242, -0.7971, -0.3984,  0.4359, -0.2210, -0.2523,  0.5205,\n",
       "          0.4092,  0.5594, -0.3456,  0.7310, -0.0219,  1.4205,  0.8356, -0.2581,\n",
       "         -0.2576, -0.1732,  0.6634,  0.0500,  0.3761, -0.2602,  0.7610, -0.5997,\n",
       "         -0.2990,  0.1505, -0.9446, -0.3265,  0.2506,  0.6285, -0.4878,  0.2138,\n",
       "         -0.9069,  0.2038,  0.2794,  0.4165, -0.5966, -0.6534, -0.9272, -1.0796,\n",
       "          0.3905,  0.1132,  0.4138,  0.3325, -1.2587, -0.7552,  0.5040, -0.4202,\n",
       "         -0.5931, -0.1967, -0.5153, -0.6308,  0.4748, -0.2482,  0.2130,  0.1514,\n",
       "          0.6684, -1.4787,  0.0515,  0.0211,  1.2472, -0.3427,  1.3741, -0.1664],\n",
       "        [-0.3384, -0.2668, -0.6970, -0.4283, -0.0406,  0.0854, -0.2727,  0.3568,\n",
       "          0.0465,  0.3050, -0.1806,  0.2830,  0.1451,  0.9886,  0.4912, -0.1916,\n",
       "          0.0816, -0.0195,  0.1905,  0.3585,  0.2618, -0.0241,  0.4258, -0.2988,\n",
       "         -0.4846,  0.3262, -0.6799, -0.5266,  0.3656,  0.4619, -0.3129,  0.0519,\n",
       "         -0.7759,  0.0415,  0.5906,  0.0372, -0.4532, -0.4106, -0.5037, -0.6221,\n",
       "          0.2962,  0.0317,  0.3200,  0.0555, -0.8152, -0.7289,  0.4661, -0.4141,\n",
       "         -0.3000, -0.3150, -0.2806, -0.5612,  0.0804, -0.2776, -0.0393, -0.1093,\n",
       "          0.2834, -0.9225, -0.0790, -0.2702,  0.4058, -0.0970,  0.7195, -0.1139],\n",
       "        [ 0.1794, -0.3527, -0.4896, -0.4916, -0.3371,  0.4582, -0.1219,  0.0992,\n",
       "         -0.3673,  0.3242,  0.1184, -0.0290,  0.3072,  0.4747, -0.0653, -0.2201,\n",
       "          0.1789,  0.3257,  0.0622,  0.4073,  0.1221,  0.2023,  0.2982, -0.0746,\n",
       "         -0.6779,  0.1317, -0.2654, -0.7220,  0.1659,  0.2819, -0.0577,  0.2477,\n",
       "         -0.4160, -0.2351,  0.7478, -0.4131, -0.1452, -0.0595,  0.0224, -0.3946,\n",
       "          0.0089,  0.0550, -0.1075, -0.1580, -0.3408, -0.5212,  0.1932, -0.2531,\n",
       "          0.0597, -0.2963, -0.0028, -0.6623, -0.1382, -0.2317, -0.2060, -0.0074,\n",
       "          0.0391, -0.4183, -0.3192, -0.4458, -0.1988, -0.0460, -0.0049, -0.2173],\n",
       "        [-0.1423, -0.2404, -0.4457, -0.1185, -0.2947,  0.4097,  0.2703, -0.0900,\n",
       "         -0.3350,  0.6091,  0.0563,  0.3805,  0.3435,  0.2993, -0.1153, -0.4092,\n",
       "          0.0265,  0.0767,  0.0410,  0.2385,  0.1274,  0.3038,  0.3698, -0.2598,\n",
       "         -0.2663, -0.0128, -0.1339, -0.3990, -0.1110,  0.0030, -0.4397,  0.1539,\n",
       "         -0.2454, -0.1376,  0.4377, -0.0226, -0.1197, -0.1413, -0.4065, -0.5764,\n",
       "          0.0270,  0.2085,  0.0641,  0.0667, -0.4147, -0.2692,  0.1440, -0.3669,\n",
       "          0.1567, -0.1646,  0.0113, -0.4704,  0.1748, -0.1012, -0.0417,  0.3015,\n",
       "          0.2492, -0.3823, -0.0974, -0.4692, -0.0432, -0.2395,  0.0652, -0.1515]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, seq_len, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = linear_layer(values)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6101e-01, -6.0720e-01,  1.9144e-01,  ..., -1.3390e-01,\n",
       "          -3.6831e-01, -5.8063e-04],\n",
       "         [-1.1647e-01,  1.3904e-02,  2.4459e-01,  ..., -2.1115e-01,\n",
       "          -2.8213e-02, -6.4046e-02],\n",
       "         [-2.5698e-01,  4.5241e-01, -5.2568e-01,  ..., -4.1626e-01,\n",
       "           2.9022e-01,  4.4190e-01],\n",
       "         [ 1.8156e-01, -1.0956e-01, -3.7014e-01,  ..., -2.6277e-01,\n",
       "          -1.5252e-01,  1.0863e-01]],\n",
       "\n",
       "        [[ 1.2181e-01, -6.3141e-02,  1.4218e-01,  ...,  6.7876e-02,\n",
       "          -2.5063e-01, -2.0321e-01],\n",
       "         [-5.0939e-01,  1.7741e-01, -1.1340e-01,  ...,  2.6057e-01,\n",
       "          -2.8749e-01,  3.4406e-01],\n",
       "         [-4.6218e-01,  7.8600e-02, -3.4274e-01,  ...,  3.4189e-01,\n",
       "           1.3583e-01,  6.8985e-03],\n",
       "         [-3.9513e-01, -7.4538e-03, -1.8200e-01,  ..., -2.7982e-02,\n",
       "           1.0435e-02,  4.8914e-02]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\", end='\\n\\n')\n",
    "\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\", end='\\n\\n')\n",
    "\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\", end='\\n\\n')\n",
    "\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\", end='\\n\\n')\n",
    "\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}\", end='\\n\\n')\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \", end='\\n\\n')\n",
    "\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\", end='\\n\\n')\n",
    "\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\", end='\\n\\n')\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([8, 128, 1024])\n",
      "\n",
      "qkv.size(): torch.Size([8, 128, 1536])\n",
      "\n",
      "qkv.size(): torch.Size([8, 128, 8, 192])\n",
      "\n",
      "qkv.size(): torch.Size([8, 8, 128, 192])\n",
      "\n",
      "q size: torch.Size([8, 8, 128, 64]), k size: torch.Size([8, 8, 128, 64]), v size: torch.Size([8, 8, 128, 64])\n",
      "\n",
      "values.size(): torch.Size([8, 8, 128, 64]), attention.size:torch.Size([8, 8, 128, 128]) \n",
      "\n",
      "values.size(): torch.Size([8, 128, 512])\n",
      "\n",
      "out.size(): torch.Size([8, 128, 512])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "sequence_length = 128\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
