{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmYGVziz50tu"
      },
      "source": [
        "- Remove non alphanumeric characters for simple training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade torch -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FOwRggVcwtzP"
      },
      "outputs": [],
      "source": [
        "from transformer import Transformer # this is the local file transformer.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6TApzOj5xCwR"
      },
      "outputs": [],
      "source": [
        "# Generated this by filtering Appendix code\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PADDING>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "bangla_vocabulary = [\n",
        "    START_TOKEN, ' ', '!', '\"', '#', '€', '$', '%', '&', \"'\", '(', ')', '*', '+', \n",
        "    ',', ';', '-', '.', '/', ':', '<', '=', '>', '?', '@',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "    '০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯'\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ',\n",
        "    'ক', 'খ', 'গ', 'ঘ', 'ঙ',\n",
        "    'চ', 'ছ', 'জ', 'ঝ', 'ঞ',\n",
        "    'ট', 'ঠ', 'ড', 'ঢ', 'ণ',\n",
        "    'ত', 'থ', 'দ', 'ধ', 'ন', \n",
        "    'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    'য', 'র', 'ল', 'শ', 'ষ', \n",
        "    'স', 'হ', 'ড়', 'ঢ', 'য়', 'ঃ', 'ং', '্',\n",
        "    'ো', 'ি', 'ৌ', 'ৗ', 'ৎ', 'ী', 'ু', 'ূ', 'ৃ', 'ৄ', 'ে', 'ৈ', '।', \n",
        "    'ঁ', 'া', '্র', '্ন',\n",
        "    PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        '[', '\\\\', ']', '^', '_', '`', \n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
        "                        'y', 'z', \n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gA8ESmCrNoc7"
      },
      "outputs": [],
      "source": [
        "index_to_bangla = {k:v for k,v in enumerate(bangla_vocabulary)}\n",
        "bangla_to_index = {v:k for k,v in enumerate(bangla_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "bn_txt_save_path = '/teamspace/studios/this_studio/Attention-Is-All-You-Need/data/bn_data.txt'\n",
        "en_txt_save_path = '/teamspace/studios/this_studio/Attention-Is-All-You-Need/data/en_data.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9SYGjRdoxRg-"
      },
      "outputs": [],
      "source": [
        "with open(en_txt_save_path, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(bn_txt_save_path, 'r') as file:\n",
        "    bangla_sentences = file.readlines()\n",
        "\n",
        "# # Limit Number of sentences\n",
        "# TOTAL_SENTENCES = 200000\n",
        "# english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "# bangla_sentences = bangla_sentences[:TOTAL_SENTENCES]\n",
        "\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "bangla_sentences = [sentence.rstrip('\\n') for sentence in bangla_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUB-BkgFxXfM",
        "outputId": "bcf7e19c-d1df-4b69-bdfa-eb74ac1a4338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"janet’s ducks lay 16 eggs per day. she eats three for breakfast every morning and bakes muffins for her friends every day with four. she sells the remainder at the farmers' market daily for $2 per fresh duck egg. how much in dollars does she make every day at the farmers' market?\",\n",
              " 'a robe takes 2 bolts of blue fiber and half that much white fiber.  how many bolts in total does it take?',\n",
              " 'josh decides to try flipping a house.  he buys a house for $80,000 and then puts in $50,000 in repairs.  this increased the value of the house by 150%.  how much profit did he make?']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OT-aznAxc5U",
        "outputId": "716c4145-fdc2-4bb0-e883-c3dcad30c2da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['জেনেটের হাঁসগুলি প্রতিদিন 16টি করে ডিম পাড়ে। তিনি প্রতিদিন প্রাতরাশে তিনটি করে ডিম খান এবং বন্ধুদের জন্য প্রতিদিন চারটি ডিম দিয়ে মাফিন তৈরি করেন। অবশিষ্ট হাঁসের ডিমগুলি তিনি প্রতিদিন কৃষকদের বাজারে প্রতি ডিম $2 দরে বিক্রয় করেন। তিনি কৃষকদের বাজারে প্রতিদিন কত ডলার উপার্জন করেন?',\n",
              " 'একটি পোশাক তৈরি করতে 2 রিল নীল সুতো এবং তার অর্ধেক সাদা সুতো লাগে। এটি তৈরি করতে মোট কতগুলি রিল লাগবে?',\n",
              " 'জোশ একটি বাড়ি ফ্লিপ করার সিদ্ধান্ত নিয়েছেন। তিনি $80,000-এ একটি বাড়ি ক্রয় করলেন এবং $50,000 দিয়ে মেরামত করলেন। এর ফলে বাড়িটির মূল্য 150% বৃদ্ধি পেল। তিনি কত ডলার লাভ করলেন?']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bangla_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8VAutsTxlaR",
        "outputId": "ff8fba72-020d-4f0c-b3c5-31c102b6fe9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97th percentile length bangla: 477.06\n",
            "97th percentile length English: 468.18\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length bangla: {np.percentile([len(x) for x in bangla_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG9ezqvaxl4b",
        "outputId": "d13be774-ca07-4333-856e-76186f71caae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 250\n",
            "Number of valid sentences: 4\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(bangla_sentences)):\n",
        "    bangla_sentence, english_sentence = bangla_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(bangla_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(bangla_sentence, bangla_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(bangla_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o80QDn4CxsV7"
      },
      "outputs": [],
      "source": [
        "bangla_sentences = [bangla_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xhLztQiLIQ",
        "outputId": "aa70ad04-2e45-4c78-c852-61e92c51a96a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['গ্রেচেনের কাছে 110টি মুদ্রা আছে। রৌপ্য মুদ্রার থেকে 30টি বেশি স্বর্ণ মুদ্রা আছে। গ্রেচেনের কাছে কতগুলি স্বর্ণ মুদ্রা আছে?',\n",
              " 'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?',\n",
              " 'জন 3 ঘণ্টা ধরে পিচ সংগ্রহ করেন। তিনি এক মিনিটে 2টি পিচ সংগ্রহ করতে পারেন। তিনি কতগুলি পিচ সংগ্রহ করেন?']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bangla_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xqOFnclmyxAE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "d_model = 512\n",
        "batch_size = 32\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 200\n",
        "kn_vocab_size = len(bangla_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model, \n",
        "                          ffn_hidden,\n",
        "                          num_heads, \n",
        "                          drop_prob, \n",
        "                          num_layers, \n",
        "                          max_sequence_length,\n",
        "                          kn_vocab_size,\n",
        "                          english_to_index,\n",
        "                          bangla_to_index,\n",
        "                          START_TOKEN, \n",
        "                          END_TOKEN, \n",
        "                          PADDING_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc2hYQk9yxX0",
        "outputId": "c060f588-6a2e-4179-9475-5acafd641f1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(71, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialEncoder(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(111, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialDecoder(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
              "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm3): LayerNormalization()\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=112, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "asUJX-STy7fg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, bangla_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.bangla_sentences = bangla_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.bangla_sentences[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-auNWjkdzDge"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentences, bangla_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roH2A4m4zF4z",
        "outputId": "f4353aa8-2f37-43b6-be0f-12aab9a35145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGeHNlzozIGF",
        "outputId": "ec3596fe-feee-426c-dce8-373fb07080fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('pancho walks 20 miles a day. except on weekends when he walks 10 miles. how many miles does he walk in a week?',\n",
              " 'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5YDttjQ0zMrv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EnjHKB1zM8Y",
        "outputId": "1a825e56-6706-46ee-85b5-ed7f0ac657fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'gretchen has 110 coins. there are 30 more gold coins than silver coins. how many gold coins does gretchen </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">have?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'pancho walks 20 miles a day. except on weekends when he walks 10 miles. how many miles does he walk in a </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">week?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'john collects peaches for 3 hours.  he can collect 2 peaches a minute.  how many peaches does he </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">collect?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'james has 6 more candies than robert. john has twice as many candies as robert. if john has 54 candies, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">how many more candies does john have than james?'</span>\n",
              "    <span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'গ্রেচেনের কাছে 110টি মুদ্রা আছে। রৌপ্য মুদ্রার থেকে 30টি বেশি স্বর্ণ মুদ্রা আছে। গ্রেচেনের কাছে কতগুলি স্বর্ণ মুদ্রা আছে?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'জন 3 ঘণ্টা ধরে পিচ সংগ্রহ করেন। তিনি এক মিনিটে 2টি পিচ সংগ্রহ করতে পারেন। তিনি কতগুলি পিচ সংগ্রহ করেন?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'জেমসের কাছে রবার্টের থেকে 6টি ক্যান্ডি বেশি আছে। জনের কাছে রবার্টের থেকে দুইগুণ বেশি ক্যান্ডি আছে। জনের কাছে যদি 54টি ক্যান্ডি থাকে তাহলে জনের কাছে জেমসের থেকে</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">কতগুলি ক্যান্ডি বেশি আছে?'</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\n",
              "        \u001b[32m'gretchen has 110 coins. there are 30 more gold coins than silver coins. how many gold coins does gretchen \u001b[0m\n",
              "\u001b[32mhave?'\u001b[0m,\n",
              "        \u001b[32m'pancho walks 20 miles a day. except on weekends when he walks 10 miles. how many miles does he walk in a \u001b[0m\n",
              "\u001b[32mweek?'\u001b[0m,\n",
              "        \u001b[32m'john collects peaches for 3 hours.  he can collect 2 peaches a minute.  how many peaches does he \u001b[0m\n",
              "\u001b[32mcollect?'\u001b[0m,\n",
              "        \u001b[32m'james has 6 more candies than robert. john has twice as many candies as robert. if john has 54 candies, \u001b[0m\n",
              "\u001b[32mhow many more candies does john have than james?'\u001b[0m\n",
              "    \u001b[1m)\u001b[0m,\n",
              "    \u001b[1m(\u001b[0m\n",
              "        \u001b[32m'গ্রেচেনের কাছে 110টি মুদ্রা আছে। রৌপ্য মুদ্রার থেকে 30টি বেশি স্বর্ণ মুদ্রা আছে। গ্রেচেনের কাছে কতগুলি স্বর্ণ মুদ্রা আছে?'\u001b[0m,\n",
              "        \u001b[32m'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?'\u001b[0m,\n",
              "        \u001b[32m'জন 3 ঘণ্টা ধরে পিচ সংগ্রহ করেন। তিনি এক মিনিটে 2টি পিচ সংগ্রহ করতে পারেন। তিনি কতগুলি পিচ সংগ্রহ করেন?'\u001b[0m,\n",
              "        \u001b[32m'জেমসের কাছে রবার্টের থেকে 6টি ক্যান্ডি বেশি আছে। জনের কাছে রবার্টের থেকে দুইগুণ বেশি ক্যান্ডি আছে। জনের কাছে যদি 54টি ক্যান্ডি থাকে তাহলে জনের কাছে জেমসের থেকে\u001b[0m\n",
              "\u001b[32mকতগুলি ক্যান্ডি বেশি আছে?'\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from rich import print\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XnanjzqtzQi8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=bangla_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_saWU5QmVem2"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdgtTSKvwN9_"
      },
      "source": [
        "Modify mask such that the padding tokens cannot look ahead.\n",
        "In Encoder, tokens before it should be -1e9 while tokens after it should be -inf.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLcXI4wkMLck"
      },
      "source": [
        "Note the target mask starts with 2 rows of non masked items: https://github.com/SamLynnEvans/Transformer/blob/master/Beam.py#L55\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju59VDGLuOqf",
        "outputId": "0ad34e31-521a-4ca2-f444-26b5374946f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Epoch \u001b[1;36m0\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask \u001b[38;5;241m=\u001b[39m create_masks(eng_batch, kn_batch)\n\u001b[1;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m kn_predictions \u001b[38;5;241m=\u001b[39m transformer(eng_batch,\n\u001b[1;32m     15\u001b[0m                              kn_batch,\n\u001b[0;32m---> 16\u001b[0m                              \u001b[43mencoder_self_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m     17\u001b[0m                              decoder_self_attention_mask\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[1;32m     18\u001b[0m                              decoder_cross_attention_mask\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     19\u001b[0m                              enc_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m                              enc_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m                              dec_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m                              dec_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39msentence_embedding\u001b[38;5;241m.\u001b[39mbatch_tokenize(kn_batch, start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterian(\n\u001b[1;32m     25\u001b[0m     kn_predictions\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kn_vocab_size)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     26\u001b[0m     labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, kn_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
        "        optim.zero_grad()\n",
        "        kn_predictions = transformer(eng_batch,\n",
        "                                     kn_batch,\n",
        "                                     encoder_self_attention_mask.to(device), \n",
        "                                     decoder_self_attention_mask.to(device), \n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == bangla_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"bangla Translation: {kn_batch[0]}\")\n",
        "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in kn_sentence_predicted:\n",
        "              if idx == bangla_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_bangla[idx.item()]\n",
        "            print(f\"bangla Prediction: {predicted_sentence}\")\n",
        "\n",
        "\n",
        "            transformer.eval()\n",
        "            kn_sentence = (\"\",)\n",
        "            eng_sentence = (\"should we go to the mall?\",)\n",
        "            for word_counter in range(max_sequence_length):\n",
        "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "                predictions = transformer(eng_sentence,\n",
        "                                          kn_sentence,\n",
        "                                          encoder_self_attention_mask.to(device), \n",
        "                                          decoder_self_attention_mask.to(device), \n",
        "                                          decoder_cross_attention_mask.to(device),\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
        "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "                next_token = index_to_bangla[next_token_index]\n",
        "                kn_sentence = (kn_sentence[0] + next_token, )\n",
        "                if next_token == END_TOKEN:\n",
        "                  break\n",
        "            \n",
        "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
        "            print(\"-------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nosVPGVijId"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOQe-juylBiJ"
      },
      "outputs": [],
      "source": [
        "transformer.eval()\n",
        "def translate(eng_sentence):\n",
        "  eng_sentence = (eng_sentence,)\n",
        "  kn_sentence = (\"\",)\n",
        "  for word_counter in range(max_sequence_length):\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "    predictions = transformer(eng_sentence,\n",
        "                              kn_sentence,\n",
        "                              encoder_self_attention_mask.to(device), \n",
        "                              decoder_self_attention_mask.to(device), \n",
        "                              decoder_cross_attention_mask.to(device),\n",
        "                              enc_start_token=False,\n",
        "                              enc_end_token=False,\n",
        "                              dec_start_token=True,\n",
        "                              dec_end_token=False)\n",
        "    next_token_prob_distribution = predictions[0][word_counter]\n",
        "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "    next_token = index_to_bangla[next_token_index]\n",
        "    kn_sentence = (kn_sentence[0] + next_token, )\n",
        "    if next_token == END_TOKEN:\n",
        "      break\n",
        "  return kn_sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDVH_YsxlK6q",
        "outputId": "83c47f99-53c0-4c2d-c26a-aaa426f50563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಇದರ ಬಗ್ಗೆ ಏನು ಮಾಡಬೇಕು?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"what should we do when the day starts?\")\n",
        "print(translation)\n",
        "#ದಿನ ಪ್ರಾರಂಭವಾದಾಗ ನಾವು ಏನು ಮಾಡಬೇಕು?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9yfawBnul0W",
        "outputId": "d9e6e6b7-683b-45f9-f013-c53c31038306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಹೇಗೆ ಇದು ಹೇಗೆ ಹೇಗೆ?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"how is this the truth?\")\n",
        "print(translation)\n",
        "#ಇದು ಹೇಗೆ ಸತ್ಯ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpdYBk5-urcQ",
        "outputId": "ca7249c5-efda-4f41-f052-ecef9691be82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಇದರಿಂದ ಮೂಲಕ ಸಂಬಂಧಿಸಿದ ಮೇಲೆ ಮಾಡಿದ್ದಾರೆ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"the world is a large place with different people\")\n",
        "print(translation)\n",
        "#ಪ್ರಪಂಚವು ವಿಭಿನ್ನ ಜನರೊಂದಿಗೆ ದೊಡ್ಡ ಸ್ಥಳವಾಗಿದೆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni9e2UYUuxi3",
        "outputId": "b93968e6-3f12-4794-b277-3a3821af221e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ನಾನು ಕುಟುಂಬದ ಹೆಸರು<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"my name is ajay\")\n",
        "print(translation)\n",
        "#ನನ್ನ ಹೆಸರು ಅಜಯ್"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJuJKHqFldW3",
        "outputId": "71aa2c6c-ec77-4b02-d39b-bd724012fb53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ನಾನು ಅಂತರ ಸಂಗತಿ ನಾನು ಕೊಡುವುದಿಲ್ಲ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"i cannot stand this smell\")\n",
        "print(translation)\n",
        "#ನಾನು ಈ ವಾಸನೆಯನ್ನು ಸಹಿಸುವುದಿಲ್ಲ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxHC4Lirlfu8",
        "outputId": "5a3ca401-abac-41af-d9db-99fb7a57fe00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಯಾವುದೇ ಕಾರಣಗಳು ಇಲ್ಲ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"noodles are the best\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLVOSI0Oli16",
        "outputId": "9f9445a1-2802-4688-900c-d7ecf2bd5c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಏಕೆ ಕಾರಣ ಏನು?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"why care about this?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStWCoAt0Ixp"
      },
      "source": [
        "This translated pretty well : \"What is the reason. Why\" without punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB6TEJfGlkRT",
        "outputId": "adb465d5-b0ed-4be4-9251-62c079f49491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಇದು ಅತ್ಯಂತ ಹೊರತಾಗಿದೆ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"this is the best thing ever\")\n",
        "print(translation)\n",
        "# ಇದು ಎಂದೆಂದಿಗೂ ಉತ್ತಮವಾಗಿದೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxsUjSybxYkh"
      },
      "source": [
        "The translation : \"This is very unusual\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQwDbuWBlmmA",
        "outputId": "7ae0e2c0-02c0-4c74-bc47-26b67da55a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ನಾನು ಕೇಳಿದ್ದೇನೆ.<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"i am here\")\n",
        "print(translation)\n",
        "# ನಾನು ಇಲ್ಲಿದ್ದೇನೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmyZ2-I6x0Yf"
      },
      "source": [
        "Translation: \"I have heard\". \n",
        "This is why word based translator may perform better than character translator. This is actually very good at optimizing the objective of the current transformer even though the translation is off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ifeV4bGluIj",
        "outputId": "6bce922d-d0db-432c-e6c6-97d482f1dea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಕ್ಯಾನ್ ಕ್ಲಿಕ್ ಕ್ಲಿಕ್ ಕ್ಲಿಕ್ ಕ್ಲಿಕ್ ಕ್ಲಿಕ್ ಮಾಡಿ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"click this\")\n",
        "print(translation)\n",
        "# ಇದನ್ನು ಕ್ಲಿಕ್ ಮಾಡಿ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RB5DUBEl1kD",
        "outputId": "9109e504-8b9e-45dc-e13c-e878b3741e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಎಲ್ಲಿ ಎಲ್ಲಿ ಎಲ್ಲಿ?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"where is the mall?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdeJ9CvMn5LM",
        "outputId": "044b5dac-29a9-4b60-e66a-4e10739a9756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಏನು ಮಾಡಬೇಕು?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"what should we do?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoikFnov1rj-"
      },
      "source": [
        "This is correct; but it absolutely fumbles on the next one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GFeyzrg1fIZ",
        "outputId": "2b4dfb04-def2-4725-9e76-5476bf85e2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಅದನ್ನು ಮಾಡಿದ ಮೇಲೆ ಮಾಡಿದ ಮಾಡಿದ್ದಾರೆ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"today, what should we do\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0upygLS-sXcO",
        "outputId": "53a62435-ab16-4d4c-8a9f-0bf07af2a501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಅದರ ಮೇಲೆ ಏಕೆ ಮಾಡಿದ್ದಾರೆ?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"why did they activate?\")\n",
        "print(translation)\n",
        "# ಅವರು ಏಕೆ ಸಕ್ರಿಯಗೊಳಿಸಿದರು?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSrsqEGmtcl2",
        "outputId": "1b8b8faa-5370-426a-f2f2-fe852696bf7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಅವರು ಏಕೆ ಅವರು ಏಕೆ ಮಾಡಿದ್ದಾರೆ?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"why did they do this?\")\n",
        "print(translation)\n",
        "# ಅವರು ಇದನ್ನು ಏಕೆ ಮಾಡಿದರು?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ISM5rd3BLJ"
      },
      "source": [
        "That turned out well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTcH2HFtyld",
        "outputId": "9dea5498-f139-4cbd-ee8c-6108e1b92fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ನಾನು ನಾನು ಕೊಡುತ್ತೇನೆ.<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"i am well.\")\n",
        "print(translation)\n",
        "# ನಾನು ಆರಾಮವಾಗಿದ್ದೇನೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP0YX2g74eP7"
      },
      "source": [
        "Translation: \"I will give you something\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pGdN13kt5Br",
        "outputId": "240256c5-f594-41b0-8218-2c70a22a156f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಇದರ ಬಗ್ಗೆ ಏನು?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"whats the word on the street?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYZ6pOe4o-X"
      },
      "source": [
        "Kind of close semantically. Translation is something like: \"What is this about\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrOcNUk1-e5"
      },
      "source": [
        "## Insights\n",
        "\n",
        "- When training, we can treat every alphabet as a single unit instead of splitting it into it's corresponding parts to preserve meaning. For example, ಮಾ should be 1 unit when comuting a loss. It should not be decomposed into ಮ + ఆ\n",
        "- Using word-based or BPE based tokenizations may help mitigate (1). Also, we will get valid word (or BPE) units if we do so. \n",
        "- Make sure the training set has a large variety of sentences that are not just about one topic like \"work\" and \"government\"\n",
        "- Increase the number of encoder / decoder units for better translations. It was set to the minimum of 1 of each unit here.\n",
        "- Create a translator with a language you understand ideally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd6_k0Uu5V7f"
      },
      "source": [
        "Overall, this model definately learned something. And you can use other languages instead of this kannada language and might see better luck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
