{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadhiin/Attention-Is-All-You-Need/blob/main/Transformer_Trainer_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmYGVziz50tu"
      },
      "source": [
        "- Remove non alphanumeric characters for simple training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T7zNJNCRxJE-",
        "outputId": "36269076-73aa-4693-c4fc-d85048c6cd53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
        "        scaled = scaled.permute(1, 0, 2, 3)\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = (torch.arange(self.max_sequence_length)\n",
        "                          .reshape(self.max_sequence_length, 1))\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE\n",
        "\n",
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "    def batch_tokenize(self, batch, start_token, end_token):\n",
        "\n",
        "        def tokenize(sentence, start_token, end_token):\n",
        "            sentence_word_indicies = [self.language_to_index[token] for token in list(sentence)]\n",
        "            if start_token:\n",
        "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "            if end_token:\n",
        "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
        "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
        "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "            return torch.tensor(sentence_word_indicies)\n",
        "\n",
        "        tokenized = []\n",
        "        for sentence_num in range(len(batch)):\n",
        "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
        "        tokenized = torch.stack(tokenized)\n",
        "        return tokenized.to(get_device())\n",
        "\n",
        "    def forward(self, x, start_token, end_token): # sentence\n",
        "        x = self.batch_tokenize(x, start_token, end_token)\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder().to(get_device())\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, sequence_length, d_model = x.size()\n",
        "        qkv = self.qkv_layer(x)\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, self_attention_mask):\n",
        "        residual_x = x.clone()\n",
        "        x = self.attention(x, mask=self_attention_mask)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + residual_x)\n",
        "        residual_x = x.clone()\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + residual_x)\n",
        "        return x\n",
        "\n",
        "class SequentialEncoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, self_attention_mask  = inputs\n",
        "        for module in self._modules.values():\n",
        "            x = module(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                      for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, self_attention_mask, start_token, end_token):\n",
        "        x = self.sentence_embedding(x, start_token, end_token)\n",
        "        x = self.layers(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n",
        "        kv = self.kv_layer(x)\n",
        "        q = self.q_layer(y)\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
        "        kv = kv.permute(0, 2, 1, 3)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k, v = kv.chunk(2, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
        "        _y = y.clone()\n",
        "        y = self.self_attention(y, mask=self_attention_mask)\n",
        "        y = self.dropout1(y)\n",
        "        y = self.layer_norm1(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
        "        y = self.dropout2(y)\n",
        "        y = self.layer_norm2(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.ffn(y)\n",
        "        y = self.dropout3(y)\n",
        "        y = self.layer_norm3(y + _y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class SequentialDecoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token):\n",
        "        y = self.sentence_embedding(y, start_token, end_token)\n",
        "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_model,\n",
        "                ffn_hidden,\n",
        "                num_heads,\n",
        "                drop_prob,\n",
        "                num_layers,\n",
        "                max_sequence_length,\n",
        "                kn_vocab_size,\n",
        "                english_to_index,\n",
        "                kannada_to_index,\n",
        "                START_TOKEN,\n",
        "                END_TOKEN,\n",
        "                PADDING_TOKEN\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, english_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, kannada_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.linear = nn.Linear(d_model, kn_vocab_size)\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    def forward(self,\n",
        "                x,\n",
        "                y,\n",
        "                encoder_self_attention_mask=None,\n",
        "                decoder_self_attention_mask=None,\n",
        "                decoder_cross_attention_mask=None,\n",
        "                enc_start_token=False,\n",
        "                enc_end_token=False,\n",
        "                dec_start_token=False, # We should make this true\n",
        "                dec_end_token=False): # x, y are batch of sentences\n",
        "        x = self.encoder(x, encoder_self_attention_mask, start_token=enc_start_token, end_token=enc_end_token)\n",
        "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token=dec_start_token, end_token=dec_end_token)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "JYEzlV3RxYK_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FOwRggVcwtzP"
      },
      "outputs": [],
      "source": [
        "# from transformer import Transformer # this is the local file transformer.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6TApzOj5xCwR"
      },
      "outputs": [],
      "source": [
        "# Generated this by filtering Appendix code\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PADDING>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "bangla_vocabulary = [\n",
        "    START_TOKEN, ' ', '!', '\"', '#', '€', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
        "    ',', ';', '-', '.', '/', ':', '<', '=', '>', '?', '@',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "    '০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯'\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ',\n",
        "    'ক', 'খ', 'গ', 'ঘ', 'ঙ',\n",
        "    'চ', 'ছ', 'জ', 'ঝ', 'ঞ',\n",
        "    'ট', 'ঠ', 'ড', 'ঢ', 'ণ',\n",
        "    'ত', 'থ', 'দ', 'ধ', 'ন',\n",
        "    'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    'য', 'র', 'ল', 'শ', 'ষ',\n",
        "    'স', 'হ', 'ড়', 'ঢ', 'য়', 'ঃ', 'ং', '্',\n",
        "    'ো', 'ি', 'ৌ', 'ৗ', 'ৎ', 'ী', 'ু', 'ূ', 'ৃ', 'ৄ', 'ে', 'ৈ', '।',\n",
        "    'ঁ', 'া', '্র', '্ন',\n",
        "    PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        '[', '\\\\', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gA8ESmCrNoc7"
      },
      "outputs": [],
      "source": [
        "index_to_bangla = {k:v for k,v in enumerate(bangla_vocabulary)}\n",
        "bangla_to_index = {v:k for k,v in enumerate(bangla_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sOQe0xI5xJFG"
      },
      "outputs": [],
      "source": [
        "# bn_txt_save_path = '/teamspace/studios/this_studio/Attention-Is-All-You-Need/data/bn_data.txt'\n",
        "# en_txt_save_path = '/teamspace/studios/this_studio/Attention-Is-All-You-Need/data/en_data.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/sadhiin/Attention-Is-All-You-Need/refs/heads/main/data/bn_data.txt'\n",
        "!wget 'https://raw.githubusercontent.com/sadhiin/Attention-Is-All-You-Need/refs/heads/main/data/en_data.txt'\n",
        "\n",
        "bn_txt_save_path = 'bn_data.txt'\n",
        "en_txt_save_path = 'en_data.txt'"
      ],
      "metadata": {
        "id": "xe0h6mSvxy5l",
        "outputId": "e45562e9-b5e7-4464-995c-fbc007fd8db0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-04 06:20:38--  https://raw.githubusercontent.com/sadhiin/Attention-Is-All-You-Need/refs/heads/main/data/bn_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155849 (152K) [text/plain]\n",
            "Saving to: ‘bn_data.txt’\n",
            "\n",
            "bn_data.txt         100%[===================>] 152.20K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-11-04 06:20:38 (50.5 MB/s) - ‘bn_data.txt’ saved [155849/155849]\n",
            "\n",
            "--2024-11-04 06:20:38--  https://raw.githubusercontent.com/sadhiin/Attention-Is-All-You-Need/refs/heads/main/data/en_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60464 (59K) [text/plain]\n",
            "Saving to: ‘en_data.txt’\n",
            "\n",
            "en_data.txt         100%[===================>]  59.05K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-11-04 06:20:38 (32.9 MB/s) - ‘en_data.txt’ saved [60464/60464]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9SYGjRdoxRg-"
      },
      "outputs": [],
      "source": [
        "with open(en_txt_save_path, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "\n",
        "with open(bn_txt_save_path, 'r') as file:\n",
        "    bangla_sentences = file.readlines()\n",
        "\n",
        "# # Limit Number of sentences\n",
        "# TOTAL_SENTENCES = 200000\n",
        "# english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "# bangla_sentences = bangla_sentences[:TOTAL_SENTENCES]\n",
        "\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "bangla_sentences = [sentence.rstrip('\\n') for sentence in bangla_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUB-BkgFxXfM",
        "outputId": "86699d1a-52c8-4de4-b32c-d2486d706272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"janet’s ducks lay 16 eggs per day. she eats three for breakfast every morning and bakes muffins for her friends every day with four. she sells the remainder at the farmers' market daily for $2 per fresh duck egg. how much in dollars does she make every day at the farmers' market?\",\n",
              " 'a robe takes 2 bolts of blue fiber and half that much white fiber.  how many bolts in total does it take?',\n",
              " 'josh decides to try flipping a house.  he buys a house for $80,000 and then puts in $50,000 in repairs.  this increased the value of the house by 150%.  how much profit did he make?']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "english_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OT-aznAxc5U",
        "outputId": "22876290-9dd6-486c-e164-6479914c71ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['জেনেটের হাঁসগুলি প্রতিদিন 16টি করে ডিম পাড়ে। তিনি প্রতিদিন প্রাতরাশে তিনটি করে ডিম খান এবং বন্ধুদের জন্য প্রতিদিন চারটি ডিম দিয়ে মাফিন তৈরি করেন। অবশিষ্ট হাঁসের ডিমগুলি তিনি প্রতিদিন কৃষকদের বাজারে প্রতি ডিম $2 দরে বিক্রয় করেন। তিনি কৃষকদের বাজারে প্রতিদিন কত ডলার উপার্জন করেন?',\n",
              " 'একটি পোশাক তৈরি করতে 2 রিল নীল সুতো এবং তার অর্ধেক সাদা সুতো লাগে। এটি তৈরি করতে মোট কতগুলি রিল লাগবে?',\n",
              " 'জোশ একটি বাড়ি ফ্লিপ করার সিদ্ধান্ত নিয়েছেন। তিনি $80,000-এ একটি বাড়ি ক্রয় করলেন এবং $50,000 দিয়ে মেরামত করলেন। এর ফলে বাড়িটির মূল্য 150% বৃদ্ধি পেল। তিনি কত ডলার লাভ করলেন?']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "bangla_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8VAutsTxlaR",
        "outputId": "7cbdb92f-8a17-4764-ee13-a9ac8ab2d6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97th percentile length bangla: 477.06\n",
            "97th percentile length English: 468.18\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length bangla: {np.percentile([len(x) for x in bangla_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG9ezqvaxl4b",
        "outputId": "1101ceef-c9ef-468f-92da-959d3358846c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 250\n",
            "Number of valid sentences: 4\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(bangla_sentences)):\n",
        "    bangla_sentence, english_sentence = bangla_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(bangla_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(bangla_sentence, bangla_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(bangla_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o80QDn4CxsV7"
      },
      "outputs": [],
      "source": [
        "bangla_sentences = [bangla_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xhLztQiLIQ",
        "outputId": "46b516b2-3860-47fe-e506-cd225b79d23b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['গ্রেচেনের কাছে 110টি মুদ্রা আছে। রৌপ্য মুদ্রার থেকে 30টি বেশি স্বর্ণ মুদ্রা আছে। গ্রেচেনের কাছে কতগুলি স্বর্ণ মুদ্রা আছে?',\n",
              " 'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?',\n",
              " 'জন 3 ঘণ্টা ধরে পিচ সংগ্রহ করেন। তিনি এক মিনিটে 2টি পিচ সংগ্রহ করতে পারেন। তিনি কতগুলি পিচ সংগ্রহ করেন?']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "bangla_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xqOFnclmyxAE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "d_model = 512\n",
        "batch_size = 32\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 200\n",
        "kn_vocab_size = len(bangla_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          kn_vocab_size,\n",
        "                          english_to_index,\n",
        "                          bangla_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc2hYQk9yxX0",
        "outputId": "0fcd103b-d71f-4de2-9c44-6b0bc429f55a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(71, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialEncoder(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(111, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialDecoder(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
              "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm3): LayerNormalization()\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=112, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "asUJX-STy7fg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, bangla_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.bangla_sentences = bangla_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.bangla_sentences[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-auNWjkdzDge"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentences, bangla_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roH2A4m4zF4z",
        "outputId": "f9035a01-5e43-43fa-8e16-3c82bc94ce9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGeHNlzozIGF",
        "outputId": "caea8dc6-d567-46e7-fd8d-12dbce4441e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pancho walks 20 miles a day. except on weekends when he walks 10 miles. how many miles does he walk in a week?',\n",
              " 'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5YDttjQ0zMrv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "9EnjHKB1zM8Y",
        "outputId": "c10554f6-48a1-4aef-d11e-e7a07344e213"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\n",
              "        \u001b[32m'gretchen has 110 coins. there are 30 more gold coins than silver coins. how many gold coins does gretchen \u001b[0m\n",
              "\u001b[32mhave?'\u001b[0m,\n",
              "        \u001b[32m'pancho walks 20 miles a day. except on weekends when he walks 10 miles. how many miles does he walk in a \u001b[0m\n",
              "\u001b[32mweek?'\u001b[0m,\n",
              "        \u001b[32m'john collects peaches for 3 hours.  he can collect 2 peaches a minute.  how many peaches does he \u001b[0m\n",
              "\u001b[32mcollect?'\u001b[0m,\n",
              "        \u001b[32m'james has 6 more candies than robert. john has twice as many candies as robert. if john has 54 candies, \u001b[0m\n",
              "\u001b[32mhow many more candies does john have than james?'\u001b[0m\n",
              "    \u001b[1m)\u001b[0m,\n",
              "    \u001b[1m(\u001b[0m\n",
              "        \u001b[32m'গ্রেচেনের কাছে 110টি মুদ্রা আছে। রৌপ্য মুদ্রার থেকে 30টি বেশি স্বর্ণ মুদ্রা আছে। গ্রেচেনের কাছে কতগুলি স্বর্ণ মুদ্রা আছে?'\u001b[0m,\n",
              "        \u001b[32m'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?'\u001b[0m,\n",
              "        \u001b[32m'জন 3 ঘণ্টা ধরে পিচ সংগ্রহ করেন। তিনি এক মিনিটে 2টি পিচ সংগ্রহ করতে পারেন। তিনি কতগুলি পিচ সংগ্রহ করেন?'\u001b[0m,\n",
              "        \u001b[32m'জেমসের কাছে রবার্টের থেকে 6টি ক্যান্ডি বেশি আছে। জনের কাছে রবার্টের থেকে দুইগুণ বেশি ক্যান্ডি আছে। জনের কাছে যদি 54টি ক্যান্ডি থাকে তাহলে জনের কাছে জেমসের থেকে\u001b[0m\n",
              "\u001b[32mকতগুলি ক্যান্ডি বেশি আছে?'\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'gretchen has 110 coins. there are 30 more gold coins than silver coins. how many gold coins does gretchen </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">have?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'pancho walks 20 miles a day. except on weekends when he walks 10 miles. how many miles does he walk in a </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">week?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'john collects peaches for 3 hours.  he can collect 2 peaches a minute.  how many peaches does he </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">collect?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'james has 6 more candies than robert. john has twice as many candies as robert. if john has 54 candies, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">how many more candies does john have than james?'</span>\n",
              "    <span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'গ্রেচেনের কাছে 110টি মুদ্রা আছে। রৌপ্য মুদ্রার থেকে 30টি বেশি স্বর্ণ মুদ্রা আছে। গ্রেচেনের কাছে কতগুলি স্বর্ণ মুদ্রা আছে?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'পাঞ্চো একদিনে 20 মাইল হাঁটেন। সপ্তাহান্তে ব্যতিরেকে তিনি 10 মাইল হাঁটেন। এক সপ্তাহে তিনি কত মাইল হাঁটেন?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'জন 3 ঘণ্টা ধরে পিচ সংগ্রহ করেন। তিনি এক মিনিটে 2টি পিচ সংগ্রহ করতে পারেন। তিনি কতগুলি পিচ সংগ্রহ করেন?'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'জেমসের কাছে রবার্টের থেকে 6টি ক্যান্ডি বেশি আছে। জনের কাছে রবার্টের থেকে দুইগুণ বেশি ক্যান্ডি আছে। জনের কাছে যদি 54টি ক্যান্ডি থাকে তাহলে জনের কাছে জেমসের থেকে</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">কতগুলি ক্যান্ডি বেশি আছে?'</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from rich import print\n",
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XnanjzqtzQi8",
        "outputId": "99508a40-a24c-4170-abc4-fdc68afffdcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from torch import nn\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=bangla_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_saWU5QmVem2"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdgtTSKvwN9_"
      },
      "source": [
        "Modify mask such that the padding tokens cannot look ahead.\n",
        "In Encoder, tokens before it should be -1e9 while tokens after it should be -inf.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLcXI4wkMLck"
      },
      "source": [
        "Note the target mask starts with 2 rows of non masked items: https://github.com/SamLynnEvans/Transformer/blob/master/Beam.py#L55\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "ju59VDGLuOqf",
        "outputId": "9a622073-dba3-4206-a194-931bf46434c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b8d9f646a9d1>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cross_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         kn_predictions = transformer(eng_batch,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                      \u001b[0mkn_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                      \u001b[0mencoder_self_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-61af1c0a5f89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask, enc_start_token, enc_end_token, dec_start_token, dec_end_token)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 dec_end_token=False): # x, y are batch of sentences\n\u001b[1;32m    301\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_start_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_end_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cross_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_start_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_end_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-61af1c0a5f89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-61af1c0a5f89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, start_token, end_token)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, kn_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
        "        optim.zero_grad()\n",
        "        kn_predictions = transformer(eng_batch,\n",
        "                                     kn_batch,\n",
        "                                     encoder_self_attention_mask.to(device),\n",
        "                                     decoder_self_attention_mask.to(device),\n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == bangla_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"bangla Translation: {kn_batch[0]}\")\n",
        "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in kn_sentence_predicted:\n",
        "              if idx == bangla_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_bangla[idx.item()]\n",
        "            print(f\"bangla Prediction: {predicted_sentence}\")\n",
        "\n",
        "\n",
        "            transformer.eval()\n",
        "            kn_sentence = (\"\",)\n",
        "            eng_sentence = (\"should we go to the mall?\",)\n",
        "            for word_counter in range(max_sequence_length):\n",
        "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "                predictions = transformer(eng_sentence,\n",
        "                                          kn_sentence,\n",
        "                                          encoder_self_attention_mask.to(device),\n",
        "                                          decoder_self_attention_mask.to(device),\n",
        "                                          decoder_cross_attention_mask.to(device),\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
        "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "                next_token = index_to_bangla[next_token_index]\n",
        "                kn_sentence = (kn_sentence[0] + next_token, )\n",
        "                if next_token == END_TOKEN:\n",
        "                  break\n",
        "\n",
        "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
        "            print(\"-------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nosVPGVijId"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOQe-juylBiJ"
      },
      "outputs": [],
      "source": [
        "transformer.eval()\n",
        "def translate(eng_sentence):\n",
        "  eng_sentence = (eng_sentence,)\n",
        "  kn_sentence = (\"\",)\n",
        "  for word_counter in range(max_sequence_length):\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "    predictions = transformer(eng_sentence,\n",
        "                              kn_sentence,\n",
        "                              encoder_self_attention_mask.to(device),\n",
        "                              decoder_self_attention_mask.to(device),\n",
        "                              decoder_cross_attention_mask.to(device),\n",
        "                              enc_start_token=False,\n",
        "                              enc_end_token=False,\n",
        "                              dec_start_token=True,\n",
        "                              dec_end_token=False)\n",
        "    next_token_prob_distribution = predictions[0][word_counter]\n",
        "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "    next_token = index_to_bangla[next_token_index]\n",
        "    kn_sentence = (kn_sentence[0] + next_token, )\n",
        "    if next_token == END_TOKEN:\n",
        "      break\n",
        "  return kn_sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDVH_YsxlK6q"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"what should we do when the day starts?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9yfawBnul0W"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"how is this the truth?\")\n",
        "print(translation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpdYBk5-urcQ"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"the world is a large place with different people\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni9e2UYUuxi3",
        "outputId": "b93968e6-3f12-4794-b277-3a3821af221e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ನಾನು ಕುಟುಂಬದ ಹೆಸರು<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"my name is ajay\")\n",
        "print(translation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJuJKHqFldW3"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"i cannot stand this smell\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxHC4Lirlfu8",
        "outputId": "5a3ca401-abac-41af-d9db-99fb7a57fe00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಯಾವುದೇ ಕಾರಣಗಳು ಇಲ್ಲ<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"noodles are the best\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLVOSI0Oli16",
        "outputId": "9f9445a1-2802-4688-900c-d7ecf2bd5c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಏಕೆ ಕಾರಣ ಏನು?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"why care about this?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStWCoAt0Ixp"
      },
      "source": [
        "This translated pretty well : \"What is the reason. Why\" without punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB6TEJfGlkRT"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"this is the best thing ever\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxsUjSybxYkh"
      },
      "source": [
        "The translation : \"This is very unusual\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQwDbuWBlmmA"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"i am here\")\n",
        "print(translation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmyZ2-I6x0Yf"
      },
      "source": [
        "Translation: \"I have heard\".\n",
        "This is why word based translator may perform better than character translator. This is actually very good at optimizing the objective of the current transformer even though the translation is off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ifeV4bGluIj"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"click this\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RB5DUBEl1kD"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"where is the mall?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdeJ9CvMn5LM"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"what should we do?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoikFnov1rj-"
      },
      "source": [
        "This is correct; but it absolutely fumbles on the next one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GFeyzrg1fIZ"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"today, what should we do\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0upygLS-sXcO"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"why did they activate?\")\n",
        "print(translation)\n",
        "# ಅವರು ಏಕೆ ಸಕ್ರಿಯಗೊಳಿಸಿದರು?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSrsqEGmtcl2"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"why did they do this?\")\n",
        "print(translation)\n",
        "# ಅವರು ಇದನ್ನು ಏಕೆ ಮಾಡಿದರು?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ISM5rd3BLJ"
      },
      "source": [
        "That turned out well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTcH2HFtyld",
        "outputId": "9dea5498-f139-4cbd-ee8c-6108e1b92fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ನಾನು ನಾನು ಕೊಡುತ್ತೇನೆ.<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"i am well.\")\n",
        "print(translation)\n",
        "# ನಾನು ಆರಾಮವಾಗಿದ್ದೇನೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP0YX2g74eP7"
      },
      "source": [
        "Translation: \"I will give you something\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pGdN13kt5Br",
        "outputId": "240256c5-f594-41b0-8218-2c70a22a156f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ಇದರ ಬಗ್ಗೆ ಏನು?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"whats the word on the street?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYZ6pOe4o-X"
      },
      "source": [
        "Kind of close semantically. Translation is something like: \"What is this about\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrOcNUk1-e5"
      },
      "source": [
        "## Insights\n",
        "\n",
        "- When training, we can treat every alphabet as a single unit instead of splitting it into it's corresponding parts to preserve meaning. For example, ಮಾ should be 1 unit when comuting a loss. It should not be decomposed into ಮ + ఆ\n",
        "- Using word-based or BPE based tokenizations may help mitigate (1). Also, we will get valid word (or BPE) units if we do so.\n",
        "- Make sure the training set has a large variety of sentences that are not just about one topic like \"work\" and \"government\"\n",
        "- Increase the number of encoder / decoder units for better translations. It was set to the minimum of 1 of each unit here.\n",
        "- Create a translator with a language you understand ideally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd6_k0Uu5V7f"
      },
      "source": [
        "Overall, this model definately learned something. And you can use other languages instead of this kannada language and might see better luck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvBs5l0wxJFj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}